{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuPVHEf5qklv"
      },
      "source": [
        "def train(train_loader, model, loss_fn, optimizer):\r\n",
        "\r\n",
        "    # switch to train mode\r\n",
        "    model.train()\r\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\r\n",
        "\r\n",
        "        prediction = model(inputs)  # model prediction\r\n",
        "        loss = loss_fn(prediction, labels) # Calucalte loss from prediction and ground truth\r\n",
        "\r\n",
        "        optimizer.zero_grad() # Initialize gradient to be zero\r\n",
        "        loss.backward() # Backpropagation from the loss\r\n",
        "        optimizer.step() # Update Parameter\r\n",
        "\r\n",
        "def accuracy(test_loader, loss_fn, criterion):\r\n",
        "\r\n",
        "    # Frozen parameter\r\n",
        "    model.eval() \r\n",
        "    _return_ = 0\r\n",
        "    for i, (inputs, labels) in enumerate(test_loader):\r\n",
        "\r\n",
        "      prediction = model(inputs) # model prediction\r\n",
        "      batch_size = prediction.shape[0] # save batch size\r\n",
        "      _, prediction = prediction.topk(1, 1, True, True) # Pick result\r\n",
        "      prediction = prediction.t() # Align Dimension\r\n",
        "      correct = (prediction == labels).sum() # Check whether model prediction is same as ground truth. And count the number of TRUE\r\n",
        "      _return_ += correct / batch_size # We need to divide by batch size \r\n",
        "    print(_return_ / (i + 1)) # We need to divide by iteration number"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4qSq0rk3fJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069aa864-e59d-492b-f169-89d4b4a3fc93"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim\r\n",
        "import torch.utils.data.distributed\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.models as models\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "num_of_batch = 20\r\n",
        "learning_rate = 0.01\r\n",
        "model = models.resnet18(pretrained=True) #Take pretrained model from torchvision\r\n",
        "num_ftrs = model.fc.in_features \r\n",
        "model.fc = nn.Linear(num_ftrs, 20) #Change the number of class to be 20\r\n",
        "\r\n",
        "loss_fn = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), learning_rate,\r\n",
        "                                momentum=0.9,\r\n",
        "                                weight_decay=1e-4)\r\n",
        "\r\n",
        "train_path = \"/content/drive/My Drive/CSE48001/dataset/train/\"\r\n",
        "test_path = \"/content/drive/My Drive/CSE48001/dataset/test/\"\r\n",
        "\r\n",
        "#Prepare the dataset for training\r\n",
        "train_dataset = datasets.ImageFolder( \r\n",
        "    train_path,\r\n",
        "    transforms.Compose([\r\n",
        "        transforms.Resize(256),\r\n",
        "        transforms.RandomCrop(224),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.5, 0.5, 0.5],\r\n",
        "                                  [0.5, 0.5, 0.5]),\r\n",
        "    ]))\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    train_dataset, batch_size=num_of_batch, shuffle=True,\r\n",
        "    pin_memory=True, sampler=None)\r\n",
        "\r\n",
        "#Prepare the dataset for testing\r\n",
        "test_dataset = datasets.ImageFolder(\r\n",
        "    test_path,\r\n",
        "    transforms.Compose([\r\n",
        "        transforms.Resize(256),\r\n",
        "        transforms.CenterCrop(224),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.5, 0.5, 0.5],\r\n",
        "                                  [0.5, 0.5, 0.5]),\r\n",
        "    ]))\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    test_dataset, batch_size=num_of_batch, shuffle=False,\r\n",
        "    pin_memory=True, sampler=None)\r\n",
        "\r\n",
        "for i in range(3):\r\n",
        "\r\n",
        "    train(train_loader, model, loss_fn, optimizer) #Train 3 epochs shows best result\r\n",
        "    accuracy(test_loader, model, loss_fn) #Print accuracy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "tensor(0.9200)\n",
            "tensor(0.8800)\n",
            "tensor(0.9100)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}